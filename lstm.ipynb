{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "694bef30-387d-4c87-bd42-810c5343cf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3532f55-d7d8-45aa-9738-d079d332b7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('google_stock_price_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc801a2a-9add-42d1-8fce-c8718288623b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/3/2017</td>\n",
       "      <td>778.81</td>\n",
       "      <td>789.63</td>\n",
       "      <td>775.80</td>\n",
       "      <td>786.14</td>\n",
       "      <td>1,657,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2017</td>\n",
       "      <td>788.36</td>\n",
       "      <td>791.34</td>\n",
       "      <td>783.16</td>\n",
       "      <td>786.90</td>\n",
       "      <td>1,073,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/5/2017</td>\n",
       "      <td>786.08</td>\n",
       "      <td>794.48</td>\n",
       "      <td>785.02</td>\n",
       "      <td>794.02</td>\n",
       "      <td>1,335,200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/6/2017</td>\n",
       "      <td>795.26</td>\n",
       "      <td>807.90</td>\n",
       "      <td>792.20</td>\n",
       "      <td>806.15</td>\n",
       "      <td>1,640,200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/9/2017</td>\n",
       "      <td>806.40</td>\n",
       "      <td>809.97</td>\n",
       "      <td>802.83</td>\n",
       "      <td>806.65</td>\n",
       "      <td>1,272,400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date    Open    High     Low   Close     Volume\n",
       "0  1/3/2017  778.81  789.63  775.80  786.14  1,657,300\n",
       "1  1/4/2017  788.36  791.34  783.16  786.90  1,073,000\n",
       "2  1/5/2017  786.08  794.48  785.02  794.02  1,335,200\n",
       "3  1/6/2017  795.26  807.90  792.20  806.15  1,640,200\n",
       "4  1/9/2017  806.40  809.97  802.83  806.65  1,272,400"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f195bfb4-b6d0-419d-947e-84d7e71a79c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Date    20 non-null     object \n",
      " 1   Open    20 non-null     float64\n",
      " 2   High    20 non-null     float64\n",
      " 3   Low     20 non-null     float64\n",
      " 4   Close   20 non-null     float64\n",
      " 5   Volume  20 non-null     object \n",
      "dtypes: float64(4), object(2)\n",
      "memory usage: 1.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73b6a6f7-9425-4bc4-b4a3-3ee5ad03a03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()  # or df.fillna(df.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67b493ff-7af1-4396-8662-2a2054f734b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bda98ca0-5ec1-490c-a716-233e09b659eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Volume'] = pd.to_numeric(df['Volume'].replace('[,:\\s]', '', regex=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "311e8263-1360-4b7e-860c-e1b361753d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date      datetime64[ns]\n",
       "Open             float64\n",
       "High             float64\n",
       "Low              float64\n",
       "Close            float64\n",
       "Volume             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "038e3ef3-c6fe-4ea2-9167-f67dced45274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Open      High       Low     Close    Volume\n",
      "0  0.000000  0.000000  0.000000  0.000000  0.317106\n",
      "1  0.161864  0.032683  0.143722  0.015344  0.066042\n",
      "2  0.123220  0.092699  0.180043  0.159095  0.178705\n",
      "3  0.278814  0.349197  0.320250  0.403998  0.309758\n",
      "4  0.467627  0.388761  0.527827  0.414092  0.151721\n"
     ]
    }
   ],
   "source": [
    "numeric_features = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaled_data = scaler.fit_transform(df[numeric_features])\n",
    "\n",
    "# Convert scaled data back into a DataFrame\n",
    "df_scaled = pd.DataFrame(scaled_data, columns=numeric_features)\n",
    "\n",
    "# Check the resulting DataFrame\n",
    "print(df_scaled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3888e6c0-f09b-4d1b-8a9c-62cc886dbade",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = pd.DataFrame(scaled_data, columns=numeric_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "effff0ae-1863-466e-a2a5-a6ecdf0a74a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Open      High       Low     Close    Volume     Close\n",
      "0  0.000000  0.000000  0.000000  0.000000  0.317106  0.000000\n",
      "1  0.161864  0.032683  0.143722  0.015344  0.066042  0.015344\n",
      "2  0.123220  0.092699  0.180043  0.159095  0.178705  0.159095\n",
      "3  0.278814  0.349197  0.320250  0.403998  0.309758  0.403998\n",
      "4  0.467627  0.388761  0.527827  0.414092  0.151721  0.414092\n"
     ]
    }
   ],
   "source": [
    "df_final = pd.concat([df_scaled, df['Close'].reset_index(drop=True)], axis=1)\n",
    "print(df_final.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11941254-5688-4520-856c-7147c46a1d01",
   "metadata": {},
   "source": [
    "Build a model to predict stock market performance using LSTM\r\n",
    "Task\r\n",
    "Model Building\r\n",
    "Import the necessary Libraries to implement LSTM. Keras deep learning library is a popular one for LSTM. It has extensive functionality and is easy to use.\r\n",
    "Run the LSTM algorithm over your train data. Once the model is built, use the test dataset to check the accuracy of the model.\r\n",
    "Plot the predicted vs actual data for the predicted duration - The last month (Jan 2017) based on the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6128c5f1-b0b4-4a99-a055-632f30e80943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5ca056bd-5bdc-4b5f-8fcc-dc1718bfb8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of scaled_data: (20, 5)\n",
      "Shape of train_data: (16, 5)\n",
      "Shape of test_data: (4, 5)\n",
      "Shape of X_train: (0,)\n",
      "Shape of y_train: (0,)\n",
      "Shape of X_test: (0,)\n",
      "Shape of y_test: (0,)\n",
      "No training sequences were created. Check the input data and sequence length.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 72\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Build LSTM Model\u001b[39;00m\n\u001b[0;32m     71\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[1;32m---> 72\u001b[0m model\u001b[38;5;241m.\u001b[39madd(LSTM(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, input_shape\u001b[38;5;241m=\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])))\n\u001b[0;32m     73\u001b[0m model\u001b[38;5;241m.\u001b[39madd(LSTM(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[0;32m     74\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m))\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Sample DataFrame creation - Replace with your actual DataFrame loading\n",
    "data = {\n",
    "    'Open': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
    "    'High': [1.1, 2.1, 3.1, 4.1, 5.1, 6.1, 7.1, 8.1, 9.1, 10.1, 11.1, 12.1, 13.1, 14.1, 15.1, 16.1, 17.1, 18.1, 19.1, 20.1],\n",
    "    'Low': [0.9, 1.9, 2.9, 3.9, 4.9, 5.9, 6.9, 7.9, 8.9, 9.9, 10.9, 11.9, 12.9, 13.9, 14.9, 15.9, 16.9, 17.9, 18.9, 19.9],\n",
    "    'Close': [1.05, 2.05, 3.05, 4.05, 5.05, 6.05, 7.05, 8.05, 9.05, 10.05, 11.05, 12.05, 13.05, 14.05, 15.05, 16.05, 17.05, 18.05, 19.05, 20.05],\n",
    "    'Volume': ['1,000', '2,000', '3,000', '4,000', '5,000', '6,000', '7,000', '8,000', '9,000', '10,000', \n",
    "               '11,000', '12,000', '13,000', '14,000', '15,000', '16,000', '17,000', '18,000', '19,000', '20,000']\n",
    "}\n",
    "df_final = pd.DataFrame(data)\n",
    "\n",
    "# Clean the Volume column by removing commas and converting to float\n",
    "df_final['Volume'] = df_final['Volume'].str.replace(',', '').astype(float)\n",
    "\n",
    "# Initialize the scaler and apply it to the entire dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(df_final[['Open', 'High', 'Low', 'Close', 'Volume']])  # Scale relevant columns\n",
    "\n",
    "# Check scaled data shape\n",
    "print(\"Shape of scaled_data:\", scaled_data.shape)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_size = int(len(scaled_data) * 0.8)\n",
    "train_data = scaled_data[:train_size]\n",
    "test_data = scaled_data[train_size:]\n",
    "\n",
    "# Check the sizes of training and testing data\n",
    "print(\"Shape of train_data:\", train_data.shape)\n",
    "print(\"Shape of test_data:\", test_data.shape)\n",
    "\n",
    "# Create sequences with a reduced sequence length\n",
    "def create_sequences(data, sequence_length=5):  # Change from 60 to 5\n",
    "    X, y = [], []\n",
    "    for i in range(sequence_length, len(data)):\n",
    "        X.append(data[i-sequence_length:i])  # Collect the past 'sequence_length' days\n",
    "        y.append(data[i, 3])  # Target variable, assuming 'Close' is at index 3\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Generate sequences for training and testing\n",
    "X_train, y_train = create_sequences(train_data, sequence_length=sequence_length)\n",
    "X_test, y_test = create_sequences(test_data, sequence_length=sequence_length)\n",
    "\n",
    "# Check the shapes of the sequences\n",
    "print(\"Shape of X_train:\", X_train.shape)  # Expecting (samples, timesteps, features)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n",
    "\n",
    "# Check for empty sequences\n",
    "if X_train.size == 0 or y_train.size == 0:\n",
    "    print(\"No training sequences were created. Check the input data and sequence length.\")\n",
    "\n",
    "# Ensure that X_train has the correct dimensions for LSTM\n",
    "if X_train.size > 0:\n",
    "    print(\"Number of features in X_train:\", X_train.shape[2])\n",
    "\n",
    "# If necessary, reshape X_train and X_test to ensure they are 3D\n",
    "if X_train.shape[0] > 0 and X_train.shape[1] > 0:\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2])\n",
    "if X_test.shape[0] > 0 and X_test.shape[1] > 0:\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2])\n",
    "\n",
    "# Build LSTM Model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(units=50, return_sequences=False))\n",
    "model.add(Dense(units=25))\n",
    "model.add(Dense(units=1))  # Output layer\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=1, epochs=5)  # Adjust epochs and batch size as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1fdd85db-6903-42b3-b9a4-ab4d883e52bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: True\n",
      "File size: 63488 bytes\n",
      "Dataset Shape: (1258, 6)\n",
      "Columns: ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
      "First 5 rows:\n",
      "       Date    Open    High     Low   Close      Volume\n",
      "0  1/3/2012  325.25  332.83  324.97  663.59   7,380,500\n",
      "1  1/4/2012  331.27  333.87  329.08  666.45   5,749,400\n",
      "2  1/5/2012  329.83  330.75  326.89  657.21   6,590,300\n",
      "3  1/6/2012  328.34  328.77  323.68  648.24   5,405,900\n",
      "4  1/9/2012  322.04  322.29  309.46  620.76  11,688,800\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# First, let's verify the file exists and check its size\n",
    "print(\"File exists:\", os.path.exists('Google_Stock_Price_Train.csv'))\n",
    "print(\"File size:\", os.path.getsize('Google_Stock_Price_Train.csv'), \"bytes\")\n",
    "\n",
    "# Set a higher recursion limit\n",
    "sys.setrecursionlimit(10000)\n",
    "\n",
    "# Read the CSV file with minimal processing\n",
    "df = pd.read_csv('Google_Stock_Price_Train.csv', encoding='utf-8')\n",
    "\n",
    "# Basic data info\n",
    "print(\"\\\n",
    "Dataset Shape:\", df.shape)\n",
    "print(\"\\\n",
    "Columns:\", df.columns.tolist())\n",
    "print(\"\\\n",
    "First 5 rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc13a675-e0af-45a0-9644-9c69db38cf78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
